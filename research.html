<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Research of Hanyuan Xiao</title>
    <meta name="description" content="Research of Hanyuan (Cornelius) Xiao">
    <meta name="keywords" content="Hanyuan,Xiao,Cornelius,Hsiao,RPI,rpi">
    <meta name="author" content="Hanyuan Xiao">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
    <!--Import Google Icon Font-->
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <!--Import materialize.css-->
    <link type="text/css" rel="stylesheet" href="css/materialize.min.css"  media="screen,projection"/>

    <!--Let browser know website is optimized for mobile-->
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <!-- CSS  -->
    <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  </head>

  <body>
    <main>
      <!-- Navigation Bar -->
      <nav class="nav-extended yellow darken-4" role="navigation">
        <div class="nav-wrapper container">
          <a id="logo-container" class="brand-logo">Research</a>
          <a href="#" data-target="nav-mobile" class="sidenav-trigger"><i class="material-icons">menu</i></a>
          <ul class="right hide-on-med-and-down">
            <li><a href="index.html">Homepage</a></li>
            <li class="active"><a href="research.html">Research</a></li>
            <li><a href="coursework.html">Coursework</a></li>
            <li><a href="publication.html">Publication</a></li>
          </ul>
        </div>

        <div class="nav-content container">
          <ul class="tabs tabs-transparent">
            <li class="tab"><a class="active" href="#Overview">Overview</a></li>
            <li class="tab"><a href="#VR_SOE">VR Acquisition & Application</a></li>
            <li class="tab"><a href="#GCVA">Google Cardboard VR/AR</a></li>
          </ul>
        </div>
      </nav>

      <ul id="nav-mobile" class="sidenav">
        <li><a href="index.html">Homepage</a></li>
        <li><a href="research.html">Research</a></li>
        <li><a href="coursework.html">Coursework</a></li>
        <li><a href="publication.html">Publication</a></li>
      </ul>

      <div id="Overview">
        <div class="container">
          <div class="section">
            <h4>2018</h4>
            <div class="divider"></div>
            <ul class="browser-default">
              <li>
                <h5>VR Acquisition & Application Development for School of Engineering Research</h5>
                <p>2018 Spring - Present</p>
                <p>This research investugates Photogrammetry technology for 3D reconstruction, as part of the new virtual and augmented reality lab for the School of Engineering. We are conducting research in method to raise the quality of Photogrammetry-generated 3D environments to make them as believable as possible, using large image datadets. We are also identifying common issues to develop best-practices guidelines for image acquisition in both indoor and outdoor environments, using combinations of off-the-shelf tools. One of our hypothesis is quality of work Photogrammetry generates can become reality-like if the size of image-dataset is approaching to infinity. The main methodology of this research is gathering documentation from various professionals in all steps of pipeline and then analyze, select and implement in our own dataset. 
                  <ul class="browser-default">
                    <li><a class="bold-text black-text">2018 Spring:</a> We have successfully captured several scenes from around the JEC building and published them in the SteamVR Workshop to allow anyone with a VR system to experience.</li>
                    <li><a class="bold-text black-text">2018 Summer:</a> We designed a program named <a class="italic-text black-text">3D-Stitching</a> to fill holes between two models, deal with mesh overlaps in between, and calculate geometry along with texture in large blank which has repeated details in real-world. We are also investigaing issue with non-planar ground surfaces to allow virtual objects to realistically interact with the generated environments.</li>
                  </ul>
                </p>
              </li>
            </ul>
          </div>
          <div class="section">
            <h4>2017</h4>
            <div class="divider"></div>
            <ul class="browser-default">
              <li><h5>Google Cardboard VR/AR</h5></li>
            </ul>
          </div>
        </div>
      </div>

      <div id="VR_SOE">
        <div class="container">
          <div class="section">
            <h4>VR Acquisition & Application</h4>
            <div class="divider"></div>
            <h5>People</h5>
            <ul class="browser-default">
              <li>Hanyuan Xiao</li>
              <li>Prof. <a href="https://www.ecse.rpi.edu/~rjradke/">Rich Radke</a>, ECSE (Advisor)</li>
            </ul>
            <h5>Abstract</h5>
            <p>
              This research investigates Photogrammetry technology for 3D model construction, as part of the new virtual and augmented reality lab for the School of Engineering. We are conducting research in method to raise the quality of Photogrammetry-generated 3D environments to make them as believable as possible, using large image datasets.  We are also identifying common issues to develop best-practices guidelines for image acquisition in both indoor and outdoor environments, using combinations of off-the-shelf tools. One of our hypothesis is quality of work Photogrammetry generates can become reality-like if the size of image-dataset is approaching to infinity. The main methodology is gathering documentation from various professionals in all steps of pipeline and then analyze, select and implement in our own dataset. So far, we have successfully captured several scenes from around the JEC and published them in the Steam workshop so that anyone with a VR headset can virtually experience these environments. Currently, we have started to analyzing and solving issues such as creating non-planar ground surfaces to allow virtual objects to realistically interact with the generated environments.
            </p>
            <h5>Poster</h5>
            <div class="container center"><img class="materialboxed" width="100%" src="src/VR_SOE/URS Poster.jpg"></div>
            <h5>Results</h5>
            <ul class="browser-default">
              <div class="row">
                <div class="col s12 m4 l4"><li><a href="https://steamcommunity.com/sharedfiles/filedetails/?id=1470661136">JEC to DCC</a></li></div>
                <div class="col s12 m4 l4"><li><a href="https://steamcommunity.com/sharedfiles/filedetails/?id=1470668582">LITEC</a></li></div>
                <div class="col s12 m4 l4"><li><a href="#">Hub</a></li></div>
              </div>
            </ul>
            <h5>Links</h5>
            <ul class="browser-default">
              <div class="row">
                <div class="col s12 m4 l4"><li><a href="http://steamcommunity.com/id/paragonch/">Steam</a></li></div>
                <div class="col s12 m4 l4"><li><a href="src/VR_SOE/Instruction for Photogrammetry.pdf">Instruction for Photogrammetry</a></li></div>
                <div class="col s12 m4 l4"><li><a href="URS Poster.jpg">URS Poster</a></li></div>
              </div>
            </ul>
          </div>

          <div class="section">
            <h4>3D-Stitching</h4>
            <div class="divider"></div>
            <h5>People</h5>
            <ul class="browser-default">
              <li>Hanyuan Xiao</li>
              <li>Ziyu Liu</li>
              <li>Prof. <a href="https://www.ecse.rpi.edu/~rjradke/">Rich Radke</a>, ECSE (Advisor)</li>
            </ul>
            <h5>Abstract</h5>
            <p>
              In this paper we describe a method to solve a particular issue within the pipeline of 3D reconstruction of large-scale scenes. Due to the linear growing rate of processing time of each image with the number of images in dataset, it is recommended to reconstruct from smaller subsets of data which are known to belong to a same object. Therefore, an automatic method to joint and merge two adjacent models is necessary to reduce the pipeline time complexity considerably. The input data in our test cases are 3D OBJ files. The method can be easily extended to other 3D model file types. Textures from original models are also recomputed to map to corresponding merged meshes. In the paper, we assume users can specify the direction in which two models are jointed and can move the surfaces to be merged to appropriate positions closed to ground truth. Output is exported in 3D OBJ type.
            </p>
            <h5>Links</h5>
            <ul class="browser-default">
              <div class="row">
                <div class="col s12 m4 l4"><li><a href="https://github.com/CorneliusHsiao/3D-Stitching">GitHub</a></li></div>
              </div>
            </ul>
          </div>
        </div>
      </div>

      <div id="GCVA">
        <div class="container">
          <div class="section">
            <h5>People</h5>
            <ul class="browser-default">
              <li>Hanyuan Xiao</li>
              <li>Shoshana Malfatto</li>
              <li>Yanjun Li</li>
              <li>Ziniu Yu</li>
              <li>Ziyang Ji</li>
              <li>Xiuqi Li</li>
              <li>Junhao Xu</li>
              <li>Carlos Power</li>
              <li>Prof. <a href="http://www.cs.rpi.edu/~moorthy/">Mukkai S. Krishnamoorthy</a>, CSCI (Advisor)</li>
            </ul>
            <h5>Abstract</h5>
            <p>
              This research 
            </p>
          </div>
        </div>
      </div>
    </main>

    <footer class="page-footer orange darken-3">
      <div class="container">
        <div class="row">
          <div class="col l6 s12">
            <h5 class="white-text">Contact</h5>
            <div><img src="src/General_info/email_research.png" alt="" class="responsive-img"></div>
            <div><img src="src/General_info/phone_research.png" alt="" class="responsive-img"></div>
          </div>
          <div class="col l4 offset-l2 s12">
            <a class="white-text">Home</a>
            <div class="divider"></div>
            <ul>
              <li><a class="white-text" href="index.html">Homepage</a></li>
              <li><a class="white-text" href="research.html">Research</a></li>
              <li><a class="white-text" href="coursework.html">Coursework</a></li>
              <li><a class="white-text" href="publication.html">Publication</a></li>
            </ul>
          </div>
        </div>
      </div>
      <div class="footer-copyright">
        <div class="container">
        Contents © 2018 Hanyuan Xiao
        </div>
      </div>
    </footer>
    
    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
    <script type="text/javascript" src="js/materialize.min.js"></script>
    <script type="text/javascript" src="js/init.js"></script>
  </body>
</html>
